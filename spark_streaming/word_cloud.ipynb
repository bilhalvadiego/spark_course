{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install nltk -qq\n",
    "# !pip3 install wordcloud -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/diegobilhalva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.11:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>WordCloud</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8cd441df00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master('local[*]')\n",
    "    .appName('WordCloud')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_tweets(df):\n",
    "    print(f'colunas: {df.columns}')\n",
    "    words = (\n",
    "        df\n",
    "        .select(\n",
    "            f.explode(f.split(f.lower('value'), ' ')).alias('word')\n",
    "        )\n",
    "        .withColumn('word', f.regexp_replace(f.col('word'), r'http\\s+',''))\n",
    "        .withColumn('word', f.regexp_replace(f.col('word'), r'@\\w+',''))\n",
    "        .withColumn('word', f.regexp_replace(f.col('word'), 'rt',''))\n",
    "        .na.replace('',None)\n",
    "        .na.drop()\n",
    "    )\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colunas: ['value']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 28\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m rows:\n\u001b[1;32m     20\u001b[0m     all_words \u001b[39m=\u001b[39m all_words \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m wordcloud \u001b[39m=\u001b[39m WordCloud(\n\u001b[1;32m     23\u001b[0m     stopwords\u001b[39m=\u001b[39;49mstops\n\u001b[1;32m     24\u001b[0m     ,background_color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mblack\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     25\u001b[0m     ,width\u001b[39m=\u001b[39;49m\u001b[39m1920\u001b[39;49m\n\u001b[1;32m     26\u001b[0m     ,height\u001b[39m=\u001b[39;49m\u001b[39m1080\u001b[39;49m\n\u001b[1;32m     27\u001b[0m     ,max_words\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m---> 28\u001b[0m )\u001b[39m.\u001b[39;49mgenerate(all_words)\n\u001b[1;32m     30\u001b[0m plt\u001b[39m.\u001b[39mcla()\n\u001b[1;32m     31\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/virtual_envs/python3107/lib/python3.10/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[0;32m~/Documents/virtual_envs/python3107/lib/python3.10/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[1;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/virtual_envs/python3107/lib/python3.10/site-packages/wordcloud/wordcloud.py:410\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    408\u001b[0m frequencies \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(frequencies\u001b[39m.\u001b[39mitems(), key\u001b[39m=\u001b[39mitemgetter(\u001b[39m1\u001b[39m), reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(frequencies) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWe need at least 1 word to plot a word cloud, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(frequencies))\n\u001b[1;32m    412\u001b[0m frequencies \u001b[39m=\u001b[39m frequencies[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_words]\n\u001b[1;32m    414\u001b[0m \u001b[39m# largest entry will be 1\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops = (\n",
    "    stopwords\n",
    "    .words('portuguese')\n",
    ")\n",
    "\n",
    "stops.append('messi')\n",
    "stops.append('https')\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        words = (\n",
    "            spark.read.parquet('../parquet')\n",
    "        )\n",
    "        \n",
    "        words = trata_tweets(words)\n",
    "        rows = words.collect()\n",
    "        all_words = ''\n",
    "        for row in rows:\n",
    "            all_words = all_words +' '+ row['word']\n",
    "        \n",
    "        wordcloud = WordCloud(\n",
    "            stopwords=stops\n",
    "            ,background_color='black'\n",
    "            ,width=1920\n",
    "            ,height=1080\n",
    "            ,max_words=100\n",
    "        ).generate(all_words)\n",
    "        \n",
    "        plt.cla()\n",
    "        plt.axis('off')\n",
    "        plt.imshow(wordcloud)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3107",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0bdab3a9dc1b8d51a730fa11c4858c711e2f56591378d76f400cf2c23e1a93e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
